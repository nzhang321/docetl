datasets:
  transcripts:
    path: data_sample.json
    type: file

default_model: openai/gpt-5-mini
bypass_cache: true

operations:
  - name: extract_filler
    type: map
    output:
      schema:
        filler_words: list[str]
    prompt: |
      Extract all instances of filler words spoken in: {{ input.content }}

pipeline:
  steps:
    - name: extract_fillers
      input: transcripts
      operations:
        - extract_filler
  output:
    type: file
    path: results_reproduce1.json

optimizer_config:
  type: moar
  save_dir: results/moar_optimization/results
  available_models:  # LiteLLM model names - ensure API keys are set in your environment
    - openai/gpt-5-mini
    - openai/gpt-5-nano
  evaluation_file: evaluate_fillers.py
  metric_key: filler_extraction_score  # This must match a key in your evaluation function's return dictionary
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-mini
  model: openai/gpt-5-mini

rate_limits:
  llm_call:
    - count: 500
      per: 1
      unit: minute
  llm_tokens:
    - count: 500000
      per: 1
      unit: minute
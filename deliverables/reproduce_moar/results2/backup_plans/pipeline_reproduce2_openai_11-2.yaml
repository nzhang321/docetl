datasets:
  transcripts:
    path: C:\Users\nickz\cuhk_app\docetl\data_sample.json
    type: file
default_model: openai/gpt-5-nano
bypass_cache: true
operations:
- name: truncate_content_head120
  type: code_map
  code: "def transform(input_doc):\n    content_content = input_doc.get('content',\
    \ '')\n    words = content_content.split()\n\n    if len(words) <= 120:\n    \
    \    # Document is short enough, keep as is\n        truncated = content_content\n\
    \    else:\n        head = ' '.join(words[:120])\n        if 0 > 0:\n        \
    \    tail = ' '.join(words[-0:])\n            truncated = head + ' ... ' + tail\n\
    \        else:\n            truncated = head\n\n    return {'content': truncated}"
- name: extract_measure_words
  type: map
  output:
    schema:
      measure_words: list[str]
  prompt: 'Extract all instances in: {{ input.content }} where the speaker uses a
    measure word. These are not numerical words but words specifying a unit such as
    "drop" in the phrase "a drop of water" or "flock" in "a flock of geese".

    '
pipeline:
  steps:
  - name: extract_measure_words
    input: transcripts
    operations:
    - truncate_content_head120
    - extract_measure_words
  output:
    type: file
    path: C:\Users\nickz\cuhk_app\docetl\results\moar_optimization\results2\pipeline_reproduce2_openai_2-2-cost.json
optimizer_config:
  type: moar
  save_dir: results/moar_optimization/results2
  available_models:
  - openai/gpt-5-mini
  - openai/gpt-5-nano
  evaluation_file: evaluate_measures.py
  metric_key: measure_extraction_score
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-mini
  model: openai/gpt-5-mini
rate_limits:
  llm_call:
  - count: 500
    per: 1
    unit: minute
  llm_tokens:
  - count: 500000
    per: 1
    unit: minute

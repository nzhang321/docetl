datasets:
  transcripts:
    path: C:\Users\nickz\cuhk_app\docetl\data_sample.json
    type: file
default_model: openai/gpt-5-nano
bypass_cache: true
operations:
- name: split_extract_measure_words
  type: split
  split_key: content
  method: token_count
  method_kwargs:
    num_tokens: 12000
    model: openai/gpt-5-nano
- name: gather_extract_measure_words
  type: gather
  content_key: content_chunk
  doc_id_key: split_extract_measure_words_id
  order_key: split_extract_measure_words_chunk_num
  peripheral_chunks:
    previous:
      head:
        count: 1
        content_key: content_chunk
      middle:
        content_key: content_chunk
      tail:
        count: 2
        content_key: content_chunk
    next:
      head:
        count: 1
        content_key: content_chunk
      middle:
        content_key: content_chunk
- name: map_extract_measure_words_chunks
  type: map
  prompt: 'You are analyzing a chunk of a larger document. Extract all instances in:
    {{ input.content_chunk_rendered }} where the speaker uses a measure word. These
    are not numerical words but words specifying a unit such as "drop" in the phrase
    "a drop of water" or "flock" in "a flock of geese".

    '
  model: openai/gpt-5-nano
  litellm_completion_kwargs:
    temperature: 0
  output:
    schema:
      measure_words: list[str]
- name: reduce_extract_measure_words
  type: reduce
  reduce_key: split_extract_measure_words_id
  prompt: 'Combine results from multiple document chunks: Extract all instances where
    the speaker uses a measure word (these are not numerical words but words specifying
    a unit such as "drop" in the phrase "a drop of water" or "flock" in "a flock of
    geese"). Combine the measure_words lists from each chunk: {% for input in inputs
    %}{{ input.measure_words | join('', '') }}{% if not loop.last %}, {% endif %}{%
    endfor %}. Remove duplicates, normalize formatting (trim whitespace, unify casing
    where appropriate), and return the final result as a JSON object with a single
    key measure_words containing a list of unique strings.'
  model: openai/gpt-5-nano
  litellm_completion_kwargs:
    temperature: 0
  output:
    schema:
      measure_words: list[str]
  associative: false
  pass_through: true
pipeline:
  steps:
  - name: extract_measure_words
    input: transcripts
    operations:
    - split_extract_measure_words
    - gather_extract_measure_words
    - map_extract_measure_words_chunks
    - reduce_extract_measure_words
  output:
    type: file
    path: C:\Users\nickz\cuhk_app\docetl\results\moar_optimization\results2\pipeline_reproduce2_openai_5.json
optimizer_config:
  type: moar
  save_dir: results/moar_optimization/results2
  available_models:
  - openai/gpt-5-mini
  - openai/gpt-5-nano
  evaluation_file: evaluate_measures.py
  metric_key: measure_extraction_score
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-mini
  model: openai/gpt-5-mini
rate_limits:
  llm_call:
  - count: 500
    per: 1
    unit: minute
  llm_tokens:
  - count: 500000
    per: 1
    unit: minute

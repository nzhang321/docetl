datasets:
  transcripts:
    path: C:\Users\nickz\cuhk_app\docetl\data_sample.json
    type: file
default_model: openai/gpt-5-nano
bypass_cache: true
operations:
- name: summarize_for_measure_extraction
  type: map
  prompt: 'Summarize the following document by extracting every occurrence of a measure
    word or unit. Include both non-numeric unit words (e.g., "a drop of water", "a
    flock of geese") and numeric measures (e.g., "two minutes", "30 percent", "800,000
    new manufacturing jobs", monetary amounts, weights, durations, counts). For each
    occurrence, produce a single line in this exact format:


    SPEAKER_LABEL || VERBATIM_PHRASE || CONTEXT_SNIPPET


    - SPEAKER_LABEL: the speaker label immediately preceding the phrase if present
    in the transcript (e.g., "JAKE TAPPER", "BIDEN"); if no speaker label is available,
    write null.

    - VERBATIM_PHRASE: the exact phrase from the original text that contains the measure
    or unit. Do NOT paraphrase, normalize, or change wordingï¿½preserve punctuation
    and numbers exactly as in the input.

    - CONTEXT_SNIPPET: up to 10 words of surrounding context (up to 5 words before
    and 5 words after the phrase), preserving original words and punctuation.


    Include every occurrence in the document (do not deduplicate). Return only the
    summary text composed of one line per occurrence as described above. If there
    are no occurrences, return an empty string. Do not add any commentary or extra
    sections.


    Document:

    {{ input.content }}'
  model: openai/gpt-5-nano
  litellm_completion_kwargs:
    temperature: 0
  output:
    schema:
      content: string
- name: extract_measure_words
  type: map
  output:
    schema:
      measure_words: list[str]
  prompt: 'Extract all instances in: {{ input.content }} where the speaker uses a
    measure word. These are not numerical words but words specifying a unit such as
    "drop" in the phrase "a drop of water" or "flock" in "a flock of geese".

    '
pipeline:
  steps:
  - name: extract_measure_words
    input: transcripts
    operations:
    - summarize_for_measure_extraction
    - extract_measure_words
  output:
    type: file
    path: C:\Users\nickz\cuhk_app\docetl\results\moar_optimization\results2\pipeline_reproduce2_openai_7.json
optimizer_config:
  type: moar
  save_dir: results/moar_optimization/results2
  available_models:
  - openai/gpt-5-mini
  - openai/gpt-5-nano
  evaluation_file: evaluate_measures.py
  metric_key: measure_extraction_score
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-mini
  model: openai/gpt-5-mini
rate_limits:
  llm_call:
  - count: 500
    per: 1
    unit: minute
  llm_tokens:
  - count: 500000
    per: 1
    unit: minute

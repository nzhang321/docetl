datasets:
  transcripts:
    path: C:\Users\nickz\cuhk_app\docetl\data_sample.json
    type: file
default_model: openai/gpt-5-nano
bypass_cache: true
operations:
- name: extract_filler
  type: map
  output:
    schema:
      filler_words: list[str]
  prompt: 'Extract all instances of filler words spoken in: {{ input.content }}

    '
  gleaning:
    validation_prompt: "You are evaluating an LLM-generated field named \"filler_words\"\
      \ that is intended to be a list of filler words and short filler phrases actually\
      \ spoken in the provided transcript. Apply the following quality checks:\n\n\
      1) Format: The output must be a non-empty JSON list of distinct strings.  \n\
      2) Verbatim extraction: Each string should be an exact excerpt of a filler word\
      \ or short filler phrase as spoken (examples: \"um\", \"uh\", \"you know\",\
      \ \"I mean\", \"like\", \"well\", \"so\", \"let me\", \"by the way\", \"frankly\"\
      , \"look\"). Do not invent or paraphrase�entries must match spoken text.  \n\
      3) Granularity and length: Entries should be short (ideally 1�3 words). Exclude\
      \ long clauses or sentence fragments that are not standalone filler tokens.\
      \  \n4) Deduplication and normalization: Remove duplicates, and avoid redundant\
      \ entries that are only case or punctuation variants. Prefer the exact verbatim\
      \ token as it appears in the transcript.  \n5) Completeness: The list should\
      \ include the clear and distinct filler tokens present in the transcript. If\
      \ many repetitions exist, include representative variants (do not require every\
      \ repeated occurrence unless it differs in form).\n\nReturn your evaluation\
      \ exactly in this format (no extra text):\n\nPASS or FAIL\n<one-line reason\
      \ summary>\nFEEDBACK: <one or more concise, actionable bullet points telling\
      \ the generator how to fix the output>\nCORRECTION: <a JSON array (list) showing\
      \ a recommended, corrected filler_words list>\n\nIf you return FAIL, make the\
      \ FEEDBACK items specific (e.g., \"remove duplicates\", \"normalize 'And so'\
      \ to 'and so' only if transcript contains that exact casing\", \"include missing\
      \ common fillers such as 'um' or 'uh' if they occur\"). If PASS, the CORRECTION\
      \ should repeat the validated list."
    num_rounds: 3
    model: openai/gpt-5-nano
pipeline:
  steps:
  - name: extract_fillers
    input: transcripts
    operations:
    - extract_filler
  output:
    type: file
    path: C:\Users\nickz\cuhk_app\docetl\results\moar_optimization\results1\pipeline_reproduce1_openai_3.json
optimizer_config:
  type: moar
  save_dir: results/moar_optimization/results1
  available_models:
  - openai/gpt-5-mini
  - openai/gpt-5-nano
  evaluation_file: evaluate_fillers.py
  metric_key: filler_extraction_score
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-mini
  model: openai/gpt-5-mini
rate_limits:
  llm_call:
  - count: 500
    per: 1
    unit: minute
  llm_tokens:
  - count: 500000
    per: 1
    unit: minute

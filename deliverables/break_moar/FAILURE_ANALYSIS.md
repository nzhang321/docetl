
# Results & Failure Analysis:

While reading the paper, I noticed that the basis for the `code_map` directive was "that relevant content can often be identified via complex regular expressions or keyword matchingâ€”that LLM agents readily synthesize" (*Wei et al.*, 2025). Thus, a larger domain of keywords or a word that cannot easily be identified by matching a unique regular expression would likely prove to be more challenging for MOAR to rewrite. My approach was therefore to create filters that encompassed a progressively larger set of words.

### Reproduce1: "Extract all instances of filler words spoken in: {{ input.content }}"
To reproduce MOAR, the first task I came up with was to create a relatively straightforward task of filtering out filler words. As the entire domain of filler words is relatively small, MOAR was able to easily create a code mapping to completely rewrite the LLM prompt (which can be seen in `reproduce_moar/results1/pipeline_reproduce1_openai_4.yaml`, `reproduce_moar/results1/pipeline_reproduce1_openai_4.yaml`, and `reproduce_moar/results1/pipeline_reproduce1_openai_4.yaml`, the three pipelines on the Pareto frontier for that pipeline). Indeed, the domain of potential filler words contained only twelve words:

```fillers = ['um', 'uh', 'like', 'you know', 'i mean', 'so', 'actually', 'basically', 'right', 'well', 'hmm', 'huh']```

<br>

### Reproduce2: *"Extract all instances in: {{ input.content }} where the speaker uses a measure word. These are not numerical words but words specifying a unit such as 'drop' in the phrase 'a drop of water' or 'flock' in 'a flock of geese'"*

The second task was to create a filter for measure words. While the domain of measure words is significantly larger (multiple dozens), it is also necessary to ensure that false positives aren't detected. Usually, this can be done by checking that the measure word appears in a regular expression of the sort "[a, \_any numerical word\_] [\_measure word\_] of [\_noun\_]"

In this case, of the four pipelines on the Pareto frontier generated by the optimizer, two of them used a code directive, `reproduce_moar/results2/pipeline_reproduce2_openai_12.yaml` and `reproduce_moar/results2/pipeline_reproduce2_openai_12.yaml`. However, the code directive in the former only mapped the document by truncating the first 200 and last 100 words, which is a basically trivial operation in terms of reducing complexity through code maps. Regardless, in the case of the latter pipeline, MOAR was able to successfully synthesize a code mapping to greatly filter the inputs for the LLM to only contextual snippets around mentions of numerical values.

  <br>


### Break: *"Extract all instances in: {{ input.content }} where the speaker mentions a place name."*
This task, which involves extracting from a potentially arbitrarily large domain of place names, naturally exceeded the capabilities of MOAR's code synthesis directive. Of the nine pipelines on the Pareto frontier for this task, only one, `break_moar/results/pipeline_break_openai_13.yaml`, rewrote it to include a code mapping, and furthermore this synthesized code mapping is another trivial truncation of the first 200 and last 100 words. Compared to the baseline pipeline's LLM output, which extracted 45 place names, the aforementioned pipeline was only able to extract 3 place names. In short, MOAR was unable to effectively leverage a code synthesis in its rewrite of this prompt.

Naturally, with a potentially infinite number of place names when considering made up place names (such as Trump's Aberbaijan that had a conflict with neighboring Albania), this task is far more difficult than the previous two examples reproducing MOAR's capabilities. While this does mean a hard coded approach is impossible, and likewise place names can show up in all sorts of contexes that makes identifying it by a regular expression extremely challenging (I don't know how to do it in a way that wouldn't just be extracting all nouns), they are still identifiable as they are a subset of proper nouns. While nouns can be tricky to extract and result in a massive set that likely wouldn't be much more efficient for the LLM to parse through, proper nouns show up very sparingly by comparison and can easily be filtered by checking for capitalization after the start of a sentence. For human English speakers/readers, this helpful characteristic for identifying place names is relatively obvious, but it comes from a lengthy process of gaining intuition and learning the explicit rules of the language. Identifying a set words of words as a subset of a meaningfully smaller (than the entire document) domain that can be composed by regular expressions or keyword matching demonstrates a short coming of MOAR's current implementation of its code synthesis directive. LLMs don't necessarily understand the language they're working with that well after all.
datasets:
  transcripts:
    path: data_sample.json
    type: file

default_model: openai/gpt-5-mini
bypass_cache: true

operations:
  - name: extract_place_names
    type: map
    output:
      schema:
        place_names: list[str]
    prompt: |
      Extract all instances in: {{ input.content }} where the speaker mentions a place name.

pipeline:
  steps:
    - name: extract_place_names
      input: transcripts
      operations:
        - extract_place_names
  output:
    type: file
    path: results_break.json

rate_limits:
  llm_call:
    - count: 500
      per: 1
      unit: minute
  llm_tokens:
    - count: 500000
      per: 1
      unit: minute
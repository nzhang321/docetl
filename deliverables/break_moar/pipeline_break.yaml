datasets:
  transcripts:
    path: data_sample.json
    type: file

default_model: openai/gpt-5-mini
bypass_cache: true

operations:
  - name: extract_place_names
    type: map
    output:
      schema:
        place_names: list[str]
    prompt: |
      Extract all instances in: {{ input.content }} where the speaker mentions a place name.

pipeline:
  steps:
    - name: extract_place_names
      input: transcripts
      operations:
        - extract_place_names
  output:
    type: file
    path: results_break.json

optimizer_config:
  type: moar
  save_dir: results/moar_optimization/results
  available_models:  # LiteLLM model names - ensure API keys are set in your environment
    - openai/gpt-5-mini
    - openai/gpt-5-nano
  evaluation_file: evaluate_place_names.py
  metric_key: place_name_extraction_score  # This must match a key in your evaluation function's return dictionary
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-mini
  model: openai/gpt-5-mini

rate_limits:
  llm_call:
    - count: 500
      per: 1
      unit: minute
  llm_tokens:
    - count: 500000
      per: 1
      unit: minute
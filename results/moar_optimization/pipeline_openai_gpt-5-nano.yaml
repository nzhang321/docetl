datasets:
  transcripts:
    path: C:\Users\nickz\cuhk_app\docetl\data.json
    type: file
default_model: openai/gpt-5-nano
operations:
- name: extract_filler
  type: map
  output:
    schema:
      filler_words: list[str]
  prompt: 'Extract all instances of filler words spoken in: {{ input.content }}

    '
pipeline:
  steps:
  - name: extract_fillers
    input: transcripts
    operations:
    - extract_filler
  output:
    type: file
    path: C:\Users\nickz\cuhk_app\docetl\results\moar_optimization\pipeline_openai_gpt-5-nano.json
optimizer_config:
  type: moar
  save_dir: results/moar_optimization
  available_models:
  - openai/gpt-5-nano
  evaluation_file: evaluate_fillers.py
  metric_key: filler_extraction_score
  max_iterations: 10
  rewrite_agent_model: openai/gpt-5-nano
  dataset_path: data.json
  model: openai/gpt-5-nano
rate_limits:
  embedding_call:
  - count: 100
    per: 1
    unit: second
  llm_call:
  - count: 100
    per: 1
    unit: second
  llm_tokens:
  - count: 1000
    per: 1
    unit: minute
